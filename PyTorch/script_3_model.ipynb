{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using {device} device')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNeuralNetwork(nn.Module) :\n",
    "    def __init__(self) :\n",
    "        super(MyNeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x) :\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyNeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Create and instance of NN and move it to Device\n",
    "\n",
    "model = MyNeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To use the model, we pass it the **input data**. \n",
    "### This executes the model’s `forward`, along with some *background operations*.\n",
    "### Do not call `model.forward()` directly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: tensor([2], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(1, 28, 28, device=device) # Random input\n",
    "logits = model(X)\n",
    "pred_prob = nn.Softmax(dim=1)(logits)\n",
    "y_pred = pred_prob.argmax(1)\n",
    "y_pred\n",
    "print(f\"Predicted class: {y_pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample random mini batch of 3 images\n",
    "ip_image = torch.rand(3, 28, 28)\n",
    "\n",
    "# flatten\n",
    "flatten = nn.Flatten()\n",
    "f_img = flatten(ip_image) # flat image\n",
    "f_img.shape\n",
    "\n",
    "# Linear \n",
    "linear_layer = nn.Linear(in_features=28*28, out_features=20)\n",
    "hidden = linear_layer(f_img) \n",
    "hidden.shape\n",
    "\n",
    "# ReLU\n",
    "print(f\"Before ReLU: {hidden}\\n\\n\")\n",
    "hidden = nn.ReLU()(hidden)\n",
    "print(f\"After ReLU: {hidden}\")\n",
    "hidden.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential\n",
    "- nn.Sequential is an ordered container of modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2926,  0.2791, -0.0297,  0.0965,  0.2100, -0.0977, -0.0172, -0.2406,\n",
       "          0.1639,  0.0310],\n",
       "        [ 0.4041,  0.2398, -0.0510,  0.0590,  0.0988, -0.1335,  0.0272, -0.1560,\n",
       "          0.2642, -0.0984],\n",
       "        [ 0.3587,  0.2055, -0.0432,  0.1264,  0.3078, -0.0731, -0.0199, -0.3034,\n",
       "          0.1657,  0.0671]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sequential\n",
    "seq_modules = nn.Sequential(\n",
    "    flatten,\n",
    "    linear_layer,\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20, 10)\n",
    ")\n",
    "\n",
    "ip_img = torch.rand(2, 28, 28)\n",
    "logits = seq_modules(ip_image)\n",
    "logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax\n",
    "- The logits are *scaled* to values **[0, 1]** representing the model’s **predicted probabilities** for each class.\n",
    "- `dim` parameter indicates the dimension along which the values must **sum to 1**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1235, 0.1218, 0.0894, 0.1015, 0.1137, 0.0836, 0.0906, 0.0724, 0.1085,\n",
       "         0.0950],\n",
       "        [0.1381, 0.1171, 0.0876, 0.0978, 0.1017, 0.0806, 0.0947, 0.0788, 0.1200,\n",
       "         0.0835],\n",
       "        [0.1300, 0.1115, 0.0870, 0.1031, 0.1236, 0.0844, 0.0890, 0.0671, 0.1072,\n",
       "         0.0971]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "pred_prob = softmax(logits)\n",
    "pred_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure:  MyNeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ") \n",
      "\n",
      "\n",
      "Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values : tensor([[-9.2748e-03, -1.2833e-02, -1.4886e-02,  ...,  3.4303e-02,\n",
      "          2.6195e-02,  2.9703e-02],\n",
      "        [-3.2315e-02, -2.2119e-02, -2.7076e-03,  ..., -2.1394e-02,\n",
      "          8.9705e-06,  1.1695e-04]], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values : tensor([0.0198, 0.0010], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values : tensor([[-0.0172,  0.0278, -0.0020,  ...,  0.0058, -0.0163,  0.0230],\n",
      "        [-0.0064, -0.0075, -0.0249,  ...,  0.0386, -0.0160,  0.0268]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values : tensor([-0.0087,  0.0284], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values : tensor([[-0.0054, -0.0178,  0.0056,  ..., -0.0264, -0.0212,  0.0041],\n",
      "        [ 0.0402, -0.0083, -0.0117,  ..., -0.0266, -0.0424,  0.0190]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.4.bias | Size: torch.Size([10]) | Values : tensor([0.0274, 0.0099], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Model structure: \", model, \"\\n\\n\")\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "408482f028cbdcad82ab472bf48df52a9213814c5f41c7acae73743007cbdc6b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('pytorch': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
